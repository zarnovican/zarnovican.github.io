<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Braňo Žarnovičan's blog</title><link>http://zarnovican.github.io/</link><description></description><atom:link href="http://zarnovican.github.io/feeds/all.rss.xml" rel="self"></atom:link><lastBuildDate>Sun, 20 May 2018 00:00:00 +0200</lastBuildDate><item><title>Why is Zoom autostarting after screen lock/unlock ?</title><link>http://zarnovican.github.io/2018/05/20/autostarting-zoom-app/</link><description>&lt;h2 id="tldr"&gt;TL;DR&lt;/h2&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;sudo sed -i &lt;span style="color: #BA2121"&gt;&amp;#39;/zoom -root/d&amp;#39;&lt;/span&gt; /usr/share/X11/app-defaults/XScreenSaver
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;.. and restart &lt;code&gt;xscreensaver&lt;/code&gt;&lt;/p&gt;
&lt;h2 id="the-problem"&gt;The Problem&lt;/h2&gt;
&lt;p&gt;I switched job recently. My new employer is using &lt;a href="https://zoom.us/"&gt;Zoom&lt;/a&gt;
for video conferencing. All internal meetings are on Zoom, as well as
any peer-to-peer talks.&lt;/p&gt;
&lt;p&gt;Zoom is also quite resource hungry. It will stay in tray unless you exit it
explicitly. I decided to start Zoom only when needed and shutdown after
the meeting.&lt;/p&gt;
&lt;p&gt;What I noticed early on, is that Zoom did auto-restart every time I left
computer for a while. Zoom login screen was greeting me every time I unlocked
my screen.&lt;/p&gt;
&lt;h2 id="dead-ends"&gt;Dead Ends&lt;/h2&gt;
&lt;p&gt;Skip this section. It's my ramblings on why it took me hours to figure it out.&lt;/p&gt;
&lt;p&gt;First, I was looking for configuration in Zoom itself. Their Settings UI,
and &lt;code&gt;~/.config/zoomus.conf&lt;/code&gt;. Nothing. Hmm.. maybe they insert a file at the right
place to be auto-executed at certain events. I checked zoom rpm content,
all pre/post-install scripts. Nothing.&lt;/p&gt;
&lt;p&gt;Then, I focused on find &lt;em&gt;who&lt;/em&gt; is executing Zoom. It had parent id 1, so no hint there.
I greped my whole &lt;code&gt;/etc&lt;/code&gt; and &lt;code&gt;$HOME&lt;/code&gt; for certain unique strings from zoom command-line.
Nothing.&lt;/p&gt;
&lt;p&gt;Then I had a brilliant idea: switch to text console after locking the computer.
There, I noticed that zoom was forked-off from xscreensaver process.&lt;/p&gt;
&lt;p&gt;Aaaaa.. ha!&lt;/p&gt;
&lt;h2 id="xscreensaver"&gt;xscreensaver&lt;/h2&gt;
&lt;p&gt;At this point, I should mention that I like my OS to be small and lean. I ditched KDE
when it became too bloated for my taste and switched to Fedora LXDE. LXDE is by default
using &lt;code&gt;xscreensaver&lt;/code&gt; for screen locking/unlocking. I don't need any fancy screensavers,
so I have none installed, just black screen is fine.&lt;/p&gt;
&lt;p&gt;So, why would &lt;code&gt;xscreensaver&lt;/code&gt; run &lt;code&gt;zoom&lt;/code&gt; app ? Is there some post-unlock hook, where Zoom
has injected itself ?&lt;/p&gt;
&lt;p&gt;Then I found &lt;code&gt;xscreensaver-demo&lt;/code&gt; and it hit me. Zoom is a screensaver app.&lt;/p&gt;
&lt;p&gt;&lt;img alt="zoom-screensaver" src="http://zarnovican.github.io/static/2018/05/20/zoom-screensaver.png" /&gt;&lt;/p&gt;
&lt;p&gt;For a while I was wandering if Zoom developers needed to be notified of lock/unlock events
to resume some long-running meetings or such. Maybe not..&lt;/p&gt;
&lt;p&gt;Then, I check &lt;code&gt;xscreensaver&lt;/code&gt; documentation on how to configure screen-saver apps.
There is a file &lt;code&gt;/usr/share/X11/app-defaults/XScreenSaver&lt;/code&gt;, which among other things
lists all available screen-saver apps&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;! You can use the `xscreensaver-demo&amp;#39; program to edit the current list of
! screen savers interactively.
!
*programs:                                                                    \
                                maze -root                                  \n\
  GL:                           superquadrics -root                         \n\
                                attraction -root                            \n\
                                blitspin -root                              \n\
...
                                vermiculate -root                           \n\
                                whirlwindwarp -root                         \n\
                                zoom -root                                  \n\
                                anemone -root                               \n\
                                apollonian -root                            \n\
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Well, apparent, in those ancient times there &lt;em&gt;was a screensaver app called zoom&lt;/em&gt; !!&lt;/p&gt;
&lt;p&gt;Is that a list of apps that are searched on some xscreensaver-specific directory ? No!
They are searched on your $PATH as well.&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;stat(&amp;quot;/usr/libexec/xscreensaver/maze&amp;quot;, 0x7ffd28e36920) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/home/zarnovic/bin/maze&amp;quot;, 0x7ffd28e36920) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/usr/lib64/qt-3.3/bin/maze&amp;quot;, 0x7ffd28e36920) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/usr/local/bin/maze&amp;quot;, 0x7ffd28e36920) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/bin/maze&amp;quot;, 0x7ffd28e36920)       = -1 ENOENT (No such file or directory)
stat(&amp;quot;/usr/bin/maze&amp;quot;, 0x7ffd28e36920)   = -1 ENOENT (No such file or directory)
stat(&amp;quot;/usr/local/sbin/maze&amp;quot;, 0x7ffd28e36920) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/usr/sbin/maze&amp;quot;, 0x7ffd28e36920)  = -1 ENOENT (No such file or directory)
stat(&amp;quot;/sbin/maze&amp;quot;, 0x7ffd28e36920)      = -1 ENOENT (No such file or directory)
stat(&amp;quot;/bin/maze&amp;quot;, 0x7ffd28e36920)       = -1 ENOENT (No such file or directory)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Because Zoom has installed &lt;code&gt;zoom&lt;/code&gt; to my PATH, it became the one and only screensaver app
(remember, I have no other screensavers installed).&lt;/p&gt;
&lt;h2 id="the-fix"&gt;The Fix&lt;/h2&gt;
&lt;p&gt;You can do several things to disable Zoom screensaver app:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;explicitly set blank screen, disabling screensaver apps&lt;/li&gt;
&lt;li&gt;disable zoom by prepending "-" in the &lt;code&gt;XScreenSaver&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;! If you want to disable a screensaver, DO NOT remove it from this list:
! instead, mark it as inactive by placing a &amp;quot;-&amp;quot; at the beginning of the line.
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;or just delete the line altogether&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;sudo sed -i &lt;span style="color: #BA2121"&gt;&amp;#39;/zoom -root/d&amp;#39;&lt;/span&gt; /usr/share/X11/app-defaults/XScreenSaver
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Braňo Žarnovičan</dc:creator><pubDate>Sun, 20 May 2018 00:00:00 +0200</pubDate><guid>tag:zarnovican.github.io,2018-05-20:2018/05/20/autostarting-zoom-app/</guid><category>zoom</category><category>autostart</category><category>xscreensaver</category><category>lock</category><category>unlock</category></item><item><title>uWSGI graceful Python code deploy</title><link>http://zarnovican.github.io/2016/02/15/uwsgi-graceful-reload/</link><description>&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#pre-fork-vs-lazy-app"&gt;Pre-fork vs Lazy-app&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#emperor-mode"&gt;Emperor mode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reload-types"&gt;Reload types&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#re-exec-master-r"&gt;re-exec master ("r")&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#restart-workers-w"&gt;restart workers ("w")&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#chain-restart-workers-c"&gt;chain restart workers ("c")&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fork-master-f"&gt;fork master ("f")&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#zerg-dance"&gt;Zerg dance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#update-upstream-config"&gt;update upstream config&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#re-exec-master-r_1"&gt;re-exec master ("r")&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#chain-restart-workers-cw"&gt;(chain) restart workers ("c"/"w")&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fork-master-f_1"&gt;fork master ("f")&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#zerg-dance_1"&gt;Zerg dance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#choosing-the-right-approach"&gt;Choosing the right approach&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#filtering-out-candidates"&gt;Filtering out candidates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#winner-fork-master"&gt;Winner: fork master&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Most likely, you have already read &lt;a href="http://uwsgi-docs.readthedocs.org/en/latest/articles/TheArtOfGracefulReloading.html"&gt;"The Art of Graceful Reloading"&lt;/a&gt;.
Although it &lt;em&gt;does&lt;/em&gt; explain a lot, it still leave gaps for the reader
to figure out. This can be quite time consuming. Well.. I went through
the exercise and this is the result.&lt;/p&gt;
&lt;p&gt;I will go through the reload types shortly, but first I need some terminology
and theoretical background on how WSGI works.&lt;/p&gt;
&lt;h2 id="pre-fork-vs-lazy-app"&gt;Pre-fork vs Lazy-app&lt;/h2&gt;
&lt;p&gt;uWSGI offers two modes how to startup your application.
In pre-fork (default), &lt;em&gt;master&lt;/em&gt; process will do the WSGI initialization, then he will fork the workers.
In lazy-app, master will first fork the workers and they do their own initialization.&lt;/p&gt;
&lt;p&gt;&lt;img alt="pre-fork vs lazy-app" src="http://zarnovican.github.io/static/2016/02/15/pre-fork.png" /&gt;&lt;/p&gt;
&lt;p&gt;(All diagrams in this post show processes as boxes. Their parent-child relation is denoted by an arrow)&lt;/p&gt;
&lt;p&gt;As you can imagine, pre-fork is much less resource intensive (memory consumption, total startup time,
time-to-spawn new worker, ..).
Lazy-app is more "robust", workers are more isolated from master and each other.&lt;/p&gt;
&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;Memory usage example&lt;/p&gt;
&lt;p&gt;Pre-forked helloworld app with 10 workers = 46M. The same app with &lt;code&gt;lazy-apps = yes&lt;/code&gt; = 225MB.
So, even two full copies of pre-forked app (92MB) are way better than lazy-apps
(depending on number of workers).&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;There is also one important difference related to code deploy.
Some types of reloads &lt;em&gt;do not reload master&lt;/em&gt;, only workers !!&lt;/p&gt;
&lt;p&gt;&lt;img alt="pre-forked workers with mixed code problem" src="http://zarnovican.github.io/static/2016/02/15/worker-only-reload.png" /&gt;&lt;/p&gt;
&lt;p&gt;This is a problem for pre-forked apps, because you may end up with old and new python modules
loaded in the same process.
During code deploy, worker would "inherit" (via &lt;code&gt;fork()&lt;/code&gt;) old version of modules already loaded by master.
While modules, not part of WSGI initialization, will be loaded from filesystem (new code).&lt;/p&gt;
&lt;p&gt;Lazyly-loaded apps are not affected.&lt;/p&gt;
&lt;h2 id="emperor-mode"&gt;Emperor mode&lt;/h2&gt;
&lt;p&gt;uWSGI can be started as an Emperor. It is a small process responsible for starting/stopping
other uWSGI processes, called vassals.
Emperor does not have any application logic, think of it as &lt;code&gt;init&lt;/code&gt; or &lt;code&gt;systemd&lt;/code&gt;.
You can create vassal by dropping an &lt;code&gt;.ini&lt;/code&gt; file into the directory.
Shutdown vassal by deleting his &lt;code&gt;.ini&lt;/code&gt; file. Simple.&lt;/p&gt;
&lt;p&gt;&lt;img alt="emperor with three vassals" src="http://zarnovican.github.io/static/2016/02/15/emperor-mode.png" /&gt;&lt;/p&gt;
&lt;p&gt;What is important to remember is that Emperor will re-spawn his vassal when he dies.
So, for example, if you gracefully shutdown old instance of your app running v1.0 code,
Emperor will happily start it again.
There is no distinction (AFAIK) between unexpected death (Emperor should restart vassal)
and administrative shutdown (Emperor should &lt;em&gt;not&lt;/em&gt; restart vassal).&lt;/p&gt;
&lt;p&gt;In addition, if you delete vassal file, Emperor will shut it down ungracefully.
Any existing http sessions will be terminated.&lt;/p&gt;
&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;Incomplete information&lt;/p&gt;
&lt;p&gt;I admit that some information in this blog post may be inaccurate.
It is based on my personal empirical experience.
In this particular case, there &lt;em&gt;may&lt;/em&gt; be obscure option to tweak vassal shutdown
but despite intensive research, I haven't found one.&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id="reload-types"&gt;Reload types&lt;/h2&gt;
&lt;p&gt;Reload can be triggered by sending the corresponding command to master FIFO pipe
(see &lt;a href="http://uwsgi-docs.readthedocs.org/en/latest/MasterFIFO.html"&gt;"The Master FIFO"&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;I will use these terms to estimate downtime/reload time:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;init&lt;/strong&gt; - time to initialize an app&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;idle-shutdown&lt;/strong&gt; - time to gracefully shutdown idle worker (time to run cleanup code)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;busy-shutdown&lt;/strong&gt; - time to gracefully shutdown busy worker
  (waiting for your longest session to finish, plus time to run cleanup code)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;N&lt;/strong&gt; - number of workers&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="re-exec-master-r"&gt;re-exec master ("r")&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://zarnovican.github.io/static/2016/02/15/reload-r.png"&gt;&lt;img alt="reload type &amp;quot;r&amp;quot;" src="http://zarnovican.github.io/static/2016/02/15/reload-r.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;master will gracefully shutdown &lt;em&gt;all&lt;/em&gt; workers at once&lt;/li&gt;
&lt;li&gt;wait until &lt;em&gt;all&lt;/em&gt; workers are down&lt;/li&gt;
&lt;li&gt;re-exec itself - basically, run new code inside the same process&lt;/li&gt;
&lt;li&gt;spawn new workers&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The problem here is that all idle workers die immediately.
Only busy workers remain.
So, during shutdown (2.), while you are waiting for your long sessions to finish,
there is &lt;em&gt;nobody&lt;/em&gt; to handle new requests.
Also, nobody will handle requests while initialization (3.) is in progress.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;downtime: busy-shutdown + init&lt;/li&gt;
&lt;li&gt;total time: ~ busy-shutdown + init&lt;/li&gt;
&lt;li&gt;master restart: yes&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="restart-workers-w"&gt;restart workers ("w")&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://zarnovican.github.io/static/2016/02/15/reload-w.png"&gt;&lt;img alt="reload type &amp;quot;w&amp;quot;" src="http://zarnovican.github.io/static/2016/02/15/reload-w.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;master will gracefully shutdown &lt;em&gt;all&lt;/em&gt; workers at once&lt;/li&gt;
&lt;li&gt;when a worker dies, it is immediately re-spawned&lt;/li&gt;
&lt;li&gt;until all workers are re-spawned&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is already better than "r", because master won't wait until &lt;em&gt;all&lt;/em&gt; workers
are down. Idle worker die/respawn in parallel, while busy workers
are left to finish their work and will respawn later.
The problem is that this will only restart workers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;downtime: idle-shutdown + init&lt;/li&gt;
&lt;li&gt;total time: ~ busy-shutdown + init&lt;/li&gt;
&lt;li&gt;master restart: NO (NOT compatible with pre-fork)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="chain-restart-workers-c"&gt;chain restart workers ("c")&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://zarnovican.github.io/static/2016/02/15/reload-c.png"&gt;&lt;img alt="reload type &amp;quot;c&amp;quot;" src="http://zarnovican.github.io/static/2016/02/15/reload-c.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;master will gracefully shutdown &lt;em&gt;one&lt;/em&gt; worker at a time (ordered by id apparently)&lt;/li&gt;
&lt;li&gt;when a worker dies, it is immediately re-spawned&lt;/li&gt;
&lt;li&gt;until all workers are re-spawned&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is the same as "w", except we shutdown/restart &lt;em&gt;one&lt;/em&gt; worker at a time.
Workers are restarted sequentially, irrespective to their status (idle/busy).
In worst case, you will wait N-times for long session to gracefully finish.&lt;/p&gt;
&lt;p&gt;Unlike "r"/"w", in this reload type, you can have a &lt;em&gt;mix&lt;/em&gt; of old/new idle workers.
So, during the reload period, new requests may be handler by either new or old code.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;downtime: none&lt;/li&gt;
&lt;li&gt;total time: ~ N x (busy-shutdown + init)&lt;/li&gt;
&lt;li&gt;master restart: NO (NOT compatible with pre-fork)&lt;/li&gt;
&lt;li&gt;mixed (old/new) code&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="fork-master-f"&gt;fork master ("f")&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://zarnovican.github.io/static/2016/02/15/reload-f.png"&gt;&lt;img alt="fork master &amp;quot;f&amp;quot;" src="http://zarnovican.github.io/static/2016/02/15/reload-f.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is technically not a reload. Master will simply fork itself and leave two copies running.
It is up to &lt;em&gt;you&lt;/em&gt; to shutdown the old one.
One possible approach is to use multiple FIFO pipes as suggested by "The Art of Graceful Reloading" doc.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;fork new master&lt;/li&gt;
&lt;li&gt;when initialization is done, it forks new workers&lt;/li&gt;
&lt;li&gt;old master is told to shutdown&lt;/li&gt;
&lt;li&gt;old master will wait until last busy worker finishes&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You don't have downtime here, but you temporarily use twice as much memory.
Forking master is considered "dangerous" (by uWSGI documentation).
There is no mix of old/new idle workers either.
New master will shutdown old master (and workers) when his workers are ready to accept queries.&lt;/p&gt;
&lt;p&gt;There is a problem with shutting down the old master.
It does not work in Emperor mode.
Emperor would re-spawn his dead vassal.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;downtime: none&lt;/li&gt;
&lt;li&gt;total time: ~ init + busy-shutdown&lt;/li&gt;
&lt;li&gt;master restart: yes&lt;/li&gt;
&lt;li&gt;NOT compatible with Emperor&lt;/li&gt;
&lt;li&gt;number of workers: 2x N&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="zerg-dance"&gt;Zerg dance&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://zarnovican.github.io/static/2016/02/15/zerg-dance.png"&gt;&lt;img alt="Zerg dance" src="http://zarnovican.github.io/static/2016/02/15/zerg-dance.png" /&gt;&lt;/a&gt;
(only the first two steps are depicted in diagram)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;start new instance (vassal)&lt;/li&gt;
&lt;li&gt;when initialization is done, it forks new workers&lt;/li&gt;
&lt;li&gt;old master is told to shutdown&lt;/li&gt;
&lt;li&gt;old master will wait until last busy worker finishes&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is similar to fork, except old and new master are not parent-child,
but siblings.
Temporarily, you would run two full copies of your app, but the mechanism of sharing
the socket for requests is different. In fork reload, the descriptor was passed from parent
to child by &lt;code&gt;fork()&lt;/code&gt;. In this mode, there is a special service (Zerg pool)
to pass the socket to new master via another control socket.&lt;/p&gt;
&lt;p&gt;Zerg pool process is quite tiny and does not contain any of your application logic.
So, you probably won't need to restart/upgrade it often.
But it is still a SPOF and quite fragile (it won't survive reload for example).&lt;/p&gt;
&lt;p&gt;As you can see, you need to start &lt;em&gt;two&lt;/em&gt; top level uWSGI processes and new one
for every code update.
Emperor is quite handy for this use case (Zerg and App server would both be top-level vassals).
You just need to be careful with shutdown/delete of old vassal.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;downtime: none&lt;/li&gt;
&lt;li&gt;total time: ~ init + busy-shutdown&lt;/li&gt;
&lt;li&gt;master restart: yes&lt;/li&gt;
&lt;li&gt;number of workers: 2x N&lt;/li&gt;
&lt;li&gt;another single point of failure&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;Zerg Pool vs Zerg Server&lt;/p&gt;
&lt;p&gt;The above information apply to "Zerg Pool". There is another Zerg (Server) which I
did not find useful for my graceful code deploy case.&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id="update-upstream-config"&gt;update upstream config&lt;/h3&gt;
&lt;p&gt;All of the above graceful reloads have one major goal in common.
To make sure there is someone listening on &lt;em&gt;the one&lt;/em&gt; socket.
It would open new possibilities if you could drop that requirement
and let each app instance listen on its own socket.
Then, you would be able to update upstream (Nginx config) to point
to the new socket, while letting existing sessions to gracefully finish
on the old one.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;start new instance (vassal)&lt;/li&gt;
&lt;li&gt;when initialization is done, it forks new workers&lt;/li&gt;
&lt;li&gt;update upstream configuration &amp;amp; reload&lt;/li&gt;
&lt;li&gt;wait until old instance (all workers) are idle&lt;/li&gt;
&lt;li&gt;delete old instance&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This approach has many of the same aspects of Zerg dance (minus the Zerg process).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;downtime: none&lt;/li&gt;
&lt;li&gt;total time: ~ init + busy-shutdown&lt;/li&gt;
&lt;li&gt;master restart: yes&lt;/li&gt;
&lt;li&gt;number of workers: 2x N&lt;/li&gt;
&lt;li&gt;changing socket name&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="examples"&gt;Examples&lt;/h2&gt;
&lt;p&gt;I will use my own &lt;a href="https://github.com/zarnovican/django-helloworld"&gt;Helloworld Django app&lt;/a&gt; to demonstrate each approach.
Examples are &lt;em&gt;minimalist&lt;/em&gt;, but fully working.
Deploy code is also cut down to bare minimum.
Your real deploy would do much, much more.
Like update DB schema, collect static files, etc.&lt;/p&gt;
&lt;p&gt;I'll be changing the code by &lt;code&gt;git checkout ..&lt;/code&gt; "in-place" because it's simpler to demonstrate.
In reality, you may want to start each new deploy from a clean copy of your checkout.&lt;/p&gt;
&lt;h3 id="re-exec-master-r_1"&gt;re-exec master ("r")&lt;/h3&gt;
&lt;p&gt;Config:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;[uwsgi]
chdir           = /home/foo/helloworld
module          = helloworld.wsgi
processes       = 4
socket          = /home/foo/var/helloworld/app.sock
master-fifo     = /home/foo/var/helloworld/master.fifo
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Code deploy:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #008000"&gt;cd&lt;/span&gt; ~/helloworld
git checkout v2.0
&lt;span style="color: #008000"&gt;echo &lt;/span&gt;r &amp;gt; ~/var/helloworld/master.fifo
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="chain-restart-workers-cw"&gt;(chain) restart workers ("c"/"w")&lt;/h3&gt;
&lt;p&gt;Config:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;[uwsgi]
chdir           = /home/foo/helloworld
module          = helloworld.wsgi
processes       = 4
socket          = /home/foo/var/helloworld/app.sock
master-fifo     = /home/foo/var/helloworld/master.fifo
lazy-apps       = true                                      # required for &amp;quot;w&amp;quot;/&amp;quot;c&amp;quot; reloads
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Code deploy:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #008000"&gt;cd&lt;/span&gt; ~/helloworld
git checkout v2.0
&lt;span style="color: #008000"&gt;echo &lt;/span&gt;w &amp;gt; ~/var/helloworld/master.fifo
&lt;span style="color: #408080; font-style: italic"&gt;# or&lt;/span&gt;
&lt;span style="color: #408080; font-style: italic"&gt;# echo c &amp;gt; ~/var/helloworld/master.fifo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="fork-master-f_1"&gt;fork master ("f")&lt;/h3&gt;
&lt;p&gt;You &lt;em&gt;cannot&lt;/em&gt; start this from Emperor.&lt;/p&gt;
&lt;p&gt;This is minimal configuration, see down below for more fine-tuned one:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;[uwsgi]
chdir           = /home/foo/helloworld
module          = helloworld.wsgi
processes       = 4
socket          = /home/foo/var/helloworld/app.sock
vacuum          = false                                     # see below for explanation
master-fifo     = /home/foo/var/helloworld/new_instance.fifo
master-fifo     = /home/foo/var/helloworld/running_instance.fifo

if-exists = /home/foo/var/helloworld/running_instance.fifo
  hook-accepting1-once = writefifo:/home/foo/var/helloworld/running_instance.fifo q
endif =
hook-accepting1-once = writefifo:/home/foo/var/helloworld/new_instance.fifo 1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Code deploy:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #008000"&gt;cd&lt;/span&gt; ~/helloworld
git checkout v2.0
&lt;span style="color: #008000"&gt;echo &lt;/span&gt;f &amp;gt; ~/var/helloworld/running_instance.fifo
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="zerg-dance_1"&gt;Zerg dance&lt;/h3&gt;
&lt;p&gt;This setup is using Emperor to start/stop vassals.&lt;/p&gt;
&lt;p&gt;Emperor startup:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #19177C"&gt;$ &lt;/span&gt;uwsgi --emperor ~/vassal
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Zerg config (~/vassal/zerg.ini):&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;[uwsgi]
zergpool = /home/foo/var/helloworld/zerg.sock:/home/foo/var/helloworld/app.sock
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vassal config (~/var/helloworld/vassal.ini):&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;[uwsgi]
chdir           = /home/foo/helloworld
module          = helloworld.wsgi
processes       = 4
socket          = /home/foo/var/helloworld/app.sock
zerg            = /home/foo/var/helloworld/zerg.sock
stats           = /home/foo/var/helloworld/%n.stats

hook-accepting1-once = write:/home/foo/var/helloworld/%n.ready ok
hook-as-user-atexit = unlink:/home/foo/var/helloworld/%n.ready
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Code deploy:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;create new vassal &lt;code&gt;vassal/helloworld-&amp;lt;newhash&amp;gt;.ini&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;wait until new vassal is up (&lt;code&gt;helloworld-&amp;lt;newhash&amp;gt;.ready&lt;/code&gt; file is created)&lt;/li&gt;
&lt;li&gt;wait until old vassal is idle (all his workers are in idle state)&lt;/li&gt;
&lt;li&gt;remove old vassal &lt;code&gt;vassal/helloworld-&amp;lt;oldhash&amp;gt;.ini&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #19177C"&gt;VERSION&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;v2.0
&lt;span style="color: #008000"&gt;cd&lt;/span&gt; ~/helloworld
git checkout &lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$VERSION&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;
&lt;span style="color: #19177C"&gt;NEW&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;quot;helloworld-&lt;/span&gt;&lt;span style="color: #008000; font-weight: bold"&gt;$(&lt;/span&gt;git rev-parse --short HEAD&lt;span style="color: #008000; font-weight: bold"&gt;)&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;
&lt;span style="color: #008000"&gt;cd&lt;/span&gt; ~/var/helloworld/
&lt;span style="color: #19177C"&gt;OLD&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;&lt;span style="color: #008000; font-weight: bold"&gt;$(&lt;/span&gt;cat current 2&amp;gt;/dev/null&lt;span style="color: #008000; font-weight: bold"&gt;)&lt;/span&gt;
cp vassal.ini ~/vassal/&lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$NEW&lt;/span&gt;&lt;span style="color: #BA2121"&gt;.ini&amp;quot;&lt;/span&gt;
&lt;span style="color: #008000; font-weight: bold"&gt;while&lt;/span&gt; &lt;span style="color: #666666"&gt;[&lt;/span&gt; ! -e &lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$NEW&lt;/span&gt;&lt;span style="color: #BA2121"&gt;.ready&amp;quot;&lt;/span&gt; &lt;span style="color: #666666"&gt;]&lt;/span&gt;; &lt;span style="color: #008000; font-weight: bold"&gt;do&lt;/span&gt; sleep 1; &lt;span style="color: #008000; font-weight: bold"&gt;done&lt;/span&gt;
&lt;span style="color: #008000"&gt;echo&lt;/span&gt; &lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$NEW&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt; &amp;gt; current
&lt;span style="color: #008000; font-weight: bold"&gt;if&lt;/span&gt; &lt;span style="color: #666666"&gt;[&lt;/span&gt; -n &lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$OLD&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt; &lt;span style="color: #666666"&gt;]&lt;/span&gt;; &lt;span style="color: #008000; font-weight: bold"&gt;then&lt;/span&gt;
    ~/bin/uwsgi-wait-for-workers.py &lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$OLD&lt;/span&gt;&lt;span style="color: #BA2121"&gt;.stats&amp;quot;&lt;/span&gt;
    rm -f ~/vassal/&lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$OLD&lt;/span&gt;&lt;span style="color: #BA2121"&gt;.ini&amp;quot;&lt;/span&gt;
&lt;span style="color: #008000; font-weight: bold"&gt;fi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The script &lt;a href="http://zarnovican.github.io/static/2016/02/15/uwsgi-wait-for-workers.py"&gt;uwsgi-wait-for-workers.py&lt;/a&gt; connects to stats socket
of a vassal and waits until all his workers are "idle".&lt;/p&gt;
&lt;h2 id="choosing-the-right-approach"&gt;Choosing the right approach&lt;/h2&gt;
&lt;p&gt;This part may be subjective.
It all depends on your requirements and use cases, which solution is better for you.&lt;/p&gt;
&lt;h3 id="filtering-out-candidates"&gt;Filtering out candidates&lt;/h3&gt;
&lt;p&gt;Summary of downsides:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;with downtime: "r"/"w" - they shutdown before starting ("r" has larger downtime)&lt;/li&gt;
&lt;li&gt;pre-fork incompatible: "w"/"c" - they don't restart master&lt;/li&gt;
&lt;li&gt;mixed responses: "c" - it has both old and new idle workers at the same time&lt;/li&gt;
&lt;li&gt;memory heavy: "f"/Zerg - they spawn full copy side-by-side&lt;/li&gt;
&lt;li&gt;Emperor incompatible: "f" - cannot allow old master to respawn&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;"r"/"w" are out due to the downtime. If your app has long sessions (like file upload),
then the downtime would be unacceptable.&lt;/p&gt;
&lt;p&gt;Zerg is quite frankly very fragile. Without zerg process, nothing works.
And you have to ask yourself questions like
"when zerg is reloaded, do I have to restart the app as well ?" and
"if both zerg/app is running, how do I know that restart is required ?"&lt;/p&gt;
&lt;p&gt;So I ended up with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"chain worker restart" - simple, but requires lazy-apps. Mixed old/new responses temporarily.&lt;/li&gt;
&lt;li&gt;"fork master" - complex, but better memory footprint. Incompatible with Emperor.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;memory argument&lt;/strong&gt; - as I have shown in "Pre-fork vs Lazy-app", two copies of pre-forked app during deploy
(fork master) is still better than one lazy-app (chain restart).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mixed responses argument&lt;/strong&gt; - this might not be such huge deal. When you deploy code on multiple machines
you would also get mixed responses. So, why would you put such restriction on multiple processes
on the same machine ? It might be better to write app to tolerate it..&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Emperor argument&lt;/strong&gt; - without Emperor, I was forced to start uWSGI directly by systemd.
If nothing else, that step made the setup more robust. This is not an argument against fork.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;complexity argument&lt;/strong&gt; - chain restart is much simpler, no doubt&lt;/p&gt;
&lt;p&gt;IMHO, the benefit of lower memory usage out-weights the simplicity of chain restart.&lt;/p&gt;
&lt;h3 id="winner-fork-master"&gt;Winner: fork master&lt;/h3&gt;
&lt;p&gt;uWSGI is executed from user's &lt;code&gt;systemd&lt;/code&gt;.
Here is the unit file (~/.config/systemd/user/helloworld.service):&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;[Unit]
Description=Helloworld Django app

[Service]
PIDFile=%h/var/helloworld/app.pid
ExecStart=/usr/local/bin/uwsgi --ini %h/.config/helloworld/uwsgi.ini
ExecReload=/home/foo/bin/fifo-write.sh f %h/var/helloworld/running_instance.fifo
KillSignal=SIGQUIT

[Install]
WantedBy=default.target
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(&lt;a href="http://zarnovican.github.io/static/2016/02/15/fifo-write.sh"&gt;fifo-write.sh&lt;/a&gt; is a simple bash script that will write to fifo in non-blocking mode)&lt;/p&gt;
&lt;p&gt;Config:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;[uwsgi]
chdir           = /home/foo/helloworld
module          = helloworld.wsgi
processes       = 4
socket          = /home/foo/var/helloworld/app.sock
pidfile         = /home/foo/var/helloworld/app.pid
vacuum          = false

hook-accepting1-once = write:/home/foo/var/helloworld/helloworld-8f88930.ready ok
hook-as-user-atexit = unlink:/home/foo/var/helloworld/helloworld-8f88930.ready

master-fifo     = /home/foo/var/helloworld/new_instance.fifo
master-fifo     = /home/foo/var/helloworld/running_instance.fifo

if-exists = /home/foo/var/helloworld/running_instance.fifo
  hook-accepting1-once = writefifo:/home/foo/var/helloworld/running_instance.fifo q
endif =
hook-accepting1-once = writefifo:/home/foo/var/helloworld/new_instance.fifo 1P
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="admonition warning"&gt;
&lt;p class="admonition-title"&gt;why vacuum=false ?&lt;/p&gt;
&lt;p&gt;During deploy, old and new master share the same socket &lt;code&gt;/home/foo/var/helloworld/app.sock&lt;/code&gt;.
With vacuum=true, old master would delete it during shutdown.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;why pid file ?&lt;/p&gt;
&lt;p&gt;Pid file is needed by systemd: a) to figure out if the service is still running,
b) where he should be sending TERM/KILL signals.
Notice, that pid file is updated by new master via fifo command "P".&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;what is that &lt;code&gt;helloworld-8f88930.ready&lt;/code&gt; file ?&lt;/p&gt;
&lt;p&gt;It is a flag to indicate that instance with hash "8f88930" has started and
it is ready to accept connections. Each instance has its own ready file.
The file is looked up during deploy, but it has no meaning afterwards.
Even there, it is not strictly necessary.
It's only a safety check.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Code deploy:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;update config file &lt;code&gt;~/.config/helloworld/uwsgi.ini&lt;/code&gt; (from template)&lt;/li&gt;
&lt;li&gt;initiate forking of master, new master will read the new config&lt;/li&gt;
&lt;li&gt;wait until new master is up (&lt;code&gt;helloworld-&amp;lt;newhash&amp;gt;.ready&lt;/code&gt; file is created)&lt;/li&gt;
&lt;li&gt;wait until old master dies&lt;/li&gt;
&lt;li&gt;do cleanup after old code is down&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #19177C"&gt;VERSION&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;v2.0
&lt;span style="color: #008000"&gt;cd&lt;/span&gt; ~/helloworld
git checkout &lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$VERSION&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;
&lt;span style="color: #19177C"&gt;NEW&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;quot;helloworld-&lt;/span&gt;&lt;span style="color: #008000; font-weight: bold"&gt;$(&lt;/span&gt;git rev-parse --short HEAD&lt;span style="color: #008000; font-weight: bold"&gt;)&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;
&lt;span style="color: #008000"&gt;cd&lt;/span&gt; ~/var/helloworld/
&lt;span style="color: #19177C"&gt;OLD_PID&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;&lt;span style="color: #008000; font-weight: bold"&gt;$(&lt;/span&gt;cat app.pid 2&amp;gt;/dev/null&lt;span style="color: #008000; font-weight: bold"&gt;)&lt;/span&gt;

cat &amp;gt; ~/.config/helloworld/uwsgi.ini &lt;span style="color: #BA2121"&gt;&amp;lt;&amp;lt;EOF&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;[uwsgi]&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;chdir           = /home/foo/helloworld&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;module          = helloworld.wsgi&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;processes       = 4&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;socket          = /home/foo/var/helloworld/app.sock&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;pidfile         = /home/foo/var/helloworld/app.pid&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;vacuum          = false&lt;/span&gt;

&lt;span style="color: #BA2121"&gt;hook-accepting1-once = write:/home/foo/var/helloworld/$NEW.ready ok&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;hook-as-user-atexit = unlink:/home/foo/var/helloworld/$NEW.ready&lt;/span&gt;

&lt;span style="color: #BA2121"&gt;master-fifo     = /home/foo/var/helloworld/new_instance.fifo&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;master-fifo     = /home/foo/var/helloworld/running_instance.fifo&lt;/span&gt;

&lt;span style="color: #BA2121"&gt;if-exists = /home/foo/var/helloworld/running_instance.fifo&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;  hook-accepting1-once = writefifo:/home/foo/var/helloworld/running_instance.fifo q&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;endif =&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;hook-accepting1-once = writefifo:/home/foo/var/helloworld/new_instance.fifo 1P&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;EOF&lt;/span&gt;

&lt;span style="color: #408080; font-style: italic"&gt;# in case of reload, this will &amp;quot;echo f &amp;gt; ~/var/helloworld/running_instance.fifo&amp;quot;&lt;/span&gt;
systemctl --user reload-or-restart helloworld

&lt;span style="color: #008000; font-weight: bold"&gt;while&lt;/span&gt; &lt;span style="color: #666666"&gt;[&lt;/span&gt; ! -e &lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$NEW&lt;/span&gt;&lt;span style="color: #BA2121"&gt;.ready&amp;quot;&lt;/span&gt; &lt;span style="color: #666666"&gt;]&lt;/span&gt;; &lt;span style="color: #008000; font-weight: bold"&gt;do&lt;/span&gt; sleep 1; &lt;span style="color: #008000; font-weight: bold"&gt;done&lt;/span&gt;
&lt;span style="color: #008000; font-weight: bold"&gt;if&lt;/span&gt; &lt;span style="color: #666666"&gt;[&lt;/span&gt; -n &lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt;&lt;span style="color: #19177C"&gt;$OLD_PID&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;quot;&lt;/span&gt; &lt;span style="color: #666666"&gt;]&lt;/span&gt;; &lt;span style="color: #008000; font-weight: bold"&gt;then&lt;/span&gt;
    &lt;span style="color: #008000; font-weight: bold"&gt;while&lt;/span&gt; &lt;span style="color: #666666"&gt;[&lt;/span&gt; -e &lt;span style="color: #BA2121"&gt;&amp;quot;/proc/&lt;/span&gt;&lt;span style="color: #19177C"&gt;$OLD_PID&lt;/span&gt;&lt;span style="color: #BA2121"&gt;/status&amp;quot;&lt;/span&gt; &lt;span style="color: #666666"&gt;]&lt;/span&gt;; &lt;span style="color: #008000; font-weight: bold"&gt;do&lt;/span&gt; sleep 1; &lt;span style="color: #008000; font-weight: bold"&gt;done&lt;/span&gt;
&lt;span style="color: #008000; font-weight: bold"&gt;fi&lt;/span&gt;
&lt;span style="color: #408080; font-style: italic"&gt;# cleanup here&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Braňo Žarnovičan</dc:creator><pubDate>Mon, 15 Feb 2016 00:00:00 +0100</pubDate><guid>tag:zarnovican.github.io,2016-02-15:2016/02/15/uwsgi-graceful-reload/</guid><category>uwsgi</category><category>python</category><category>Django</category><category>systemd</category></item><item><title>Run cloud image without cloud</title><link>http://zarnovican.github.io/2015/11/10/run-cloud-image-without-cloud/</link><description>&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#for-the-impatient"&gt;For the impatient&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#motivation"&gt;Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#before-you-begin"&gt;Before You Begin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#preparation"&gt;Preparation&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#install-qemulibvirt"&gt;Install qemu/libvirt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configure-network"&gt;Configure network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configure-storage"&gt;Configure storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-minimal-config-drive"&gt;Create minimal config drive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-vm"&gt;Create VM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#and-we-are-done"&gt;And we are done..&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-vms-base-image"&gt;What is VM's base image ?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#re-image-the-vm"&gt;Re-image the VM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#troubleshooting-cloud-init"&gt;Troubleshooting cloud-init&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#extras"&gt;Extras&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#static-host-ssh-key"&gt;Static host ssh key&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="for-the-impatient"&gt;For the impatient&lt;/h2&gt;
&lt;p&gt;Modern cloud images have &lt;code&gt;cloud-init&lt;/code&gt; pre-installed. You can feed cloud-init bootstrap
information via iso image attached as cdrom device, so called &lt;em&gt;config drive&lt;/em&gt;.
There, you can store 1) meta-data as if they were provided by cloud, 2) user-data as if they were
specified on VM creation.&lt;/p&gt;
&lt;p&gt;For the minimal setup, you only need the meta-data with the public key.
Here is how the iso content should look like:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;.
└── openstack
    └── latest
        └── meta_data.json
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Where &lt;code&gt;meta_data.json&lt;/code&gt; looks like:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;{
    &lt;span style="color: #008000; font-weight: bold"&gt;&amp;quot;public_keys&amp;quot;&lt;/span&gt;: {
        &lt;span style="color: #008000; font-weight: bold"&gt;&amp;quot;&amp;lt;arbitrary-key-name&amp;gt;&amp;quot;&lt;/span&gt;: &lt;span style="color: #BA2121"&gt;&amp;quot;ssh-rsa &amp;lt;public-key&amp;gt;\n&amp;quot;&lt;/span&gt;
    },
    &lt;span style="color: #008000; font-weight: bold"&gt;&amp;quot;uuid&amp;quot;&lt;/span&gt;: &lt;span style="color: #BA2121"&gt;&amp;quot;&amp;lt;any-uuid-value&amp;gt;&amp;quot;&lt;/span&gt;
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At boot time, public key is injected into cloud user's &lt;code&gt;authorized_keys&lt;/code&gt; file (eg. "centos" user for CentOS cloud image).&lt;/p&gt;
&lt;h2 id="motivation"&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Installing VM from installation media ? Hell, no!
At least not if you intend to drop &amp;amp; re-create your VM repeatedly.
You have DHCP/PXE/Kickstart to automate it, you know..
Well, ok, but not if you need something working.. like now.&lt;/p&gt;
&lt;p&gt;Vagrant ?
Weeeell, maybe the config written in Ruby is not your thing.
Or the image you want to run is not public and you have only Qcow2 version and no Vagrant.&lt;/p&gt;
&lt;p&gt;Or simply, you don't intend to test software on your VM, rather deployment automation (Ansible, Puppet, ..)
In which case, you probably want to test it on exactly the same image as in the cloud.&lt;/p&gt;
&lt;p&gt;(Or you just want to do it by hand for the sake of it)&lt;/p&gt;
&lt;h2 id="before-you-begin"&gt;Before You Begin&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Openstack images have no default root password or password-less account.
You &lt;em&gt;can&lt;/em&gt; run the image as-is, but you won't be able to login.
That's where &lt;em&gt;config drive&lt;/em&gt; comes in.
Simply put, it's an iso image attached as cdrom to the VM.&lt;/p&gt;
&lt;p&gt;I did enhance this guide a bit to allow &lt;em&gt;sharing&lt;/em&gt; of the same base image by several instances.
This step is completely optional.
It won't affect the config drive if you skip it.&lt;/p&gt;
&lt;p&gt;I'll be using Fedora as host, but you should be able to adapt the examples easily to your distro.&lt;/p&gt;
&lt;p&gt;It does not matter what image you want to run in the guest VM as long as
it has cloud-init pre-installed.&lt;/p&gt;
&lt;h2 id="preparation"&gt;Preparation&lt;/h2&gt;
&lt;h3 id="install-qemulibvirt"&gt;Install qemu/libvirt&lt;/h3&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #408080; font-style: italic"&gt;# install packages from &amp;quot;virtualization&amp;quot; group&lt;/span&gt;
sudo dnf install @virtualization -y

&lt;span style="color: #408080; font-style: italic"&gt;# start libvirtd&lt;/span&gt;
sudo systemctl start libvirtd
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="configure-network"&gt;Configure network&lt;/h3&gt;
&lt;p&gt;VM running in the cloud receives IP address and hostname from the cloud provider via DHCP.
In your libvirt setup, VM would get a random IP from the pool and NO hostname.
Let's fix that first..&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #408080; font-style: italic"&gt;# edit &amp;#39;default&amp;#39; network and add static DHCP&lt;/span&gt;
sudo virsh net-edit default
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Snippet that should be added inside &lt;code&gt;&amp;lt;dhcp&amp;gt;&lt;/code&gt; tag (I'm assuming that your default network
has the same range as mine - 192.168.122.0/24):&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #008000; font-weight: bold"&gt;&amp;lt;dhcp&amp;gt;&lt;/span&gt;
  ...
  &lt;span style="color: #008000; font-weight: bold"&gt;&amp;lt;host&lt;/span&gt; &lt;span style="color: #7D9029"&gt;mac=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;52:54:00:00:00:11&amp;#39;&lt;/span&gt; &lt;span style="color: #7D9029"&gt;name=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;vm1&amp;#39;&lt;/span&gt; &lt;span style="color: #7D9029"&gt;ip=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;192.168.122.11&amp;#39;&lt;/span&gt;&lt;span style="color: #008000; font-weight: bold"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span style="color: #008000; font-weight: bold"&gt;&amp;lt;host&lt;/span&gt; &lt;span style="color: #7D9029"&gt;mac=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;52:54:00:00:00:12&amp;#39;&lt;/span&gt; &lt;span style="color: #7D9029"&gt;name=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;vm2&amp;#39;&lt;/span&gt; &lt;span style="color: #7D9029"&gt;ip=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;192.168.122.12&amp;#39;&lt;/span&gt;&lt;span style="color: #008000; font-weight: bold"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span style="color: #008000; font-weight: bold"&gt;&amp;lt;host&lt;/span&gt; &lt;span style="color: #7D9029"&gt;mac=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;52:54:00:00:00:13&amp;#39;&lt;/span&gt; &lt;span style="color: #7D9029"&gt;name=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;vm3&amp;#39;&lt;/span&gt; &lt;span style="color: #7D9029"&gt;ip=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;192.168.122.13&amp;#39;&lt;/span&gt;&lt;span style="color: #008000; font-weight: bold"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span style="color: #008000; font-weight: bold"&gt;&amp;lt;host&lt;/span&gt; &lt;span style="color: #7D9029"&gt;mac=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;52:54:00:00:00:14&amp;#39;&lt;/span&gt; &lt;span style="color: #7D9029"&gt;name=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;vm4&amp;#39;&lt;/span&gt; &lt;span style="color: #7D9029"&gt;ip=&lt;/span&gt;&lt;span style="color: #BA2121"&gt;&amp;#39;192.168.122.14&amp;#39;&lt;/span&gt;&lt;span style="color: #008000; font-weight: bold"&gt;/&amp;gt;&lt;/span&gt;
&lt;span style="color: #008000; font-weight: bold"&gt;&amp;lt;/dhcp&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;Why static MAC ?&lt;/p&gt;
&lt;p&gt;The MAC address will later be used when creating the VM.
It is IMHO easier to &lt;em&gt;provide&lt;/em&gt; MAC to VM, rather than &lt;em&gt;fetch&lt;/em&gt; (randomly generated) MAC from VM.
Also, you only need to define this mapping &lt;em&gt;once&lt;/em&gt;, no matter how many VMs you intend
to run.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Apply changes by restarting &lt;code&gt;dnsmasq&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;sudo virsh net-destroy default
sudo virsh net-start   default
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(optional) You might want to add your VMs to &lt;code&gt;/etc/hosts&lt;/code&gt; file:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;...
192.168.122.11  vm1
192.168.122.12  vm2
192.168.122.13  vm3
192.168.122.14  vm4
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="configure-storage"&gt;Configure storage&lt;/h3&gt;
&lt;p&gt;OK, now is the time to decide which image you want to run inside the guest.
Decent distros provide pre-built Qcow2 images ready to be imported to Openstack.
Here is a good source: &lt;a href="http://docs.openstack.org/image-guide/content/ch_obtaining_images.html"&gt;"Get images" in Openstack's doc&lt;/a&gt;.
Download one of them..&lt;/p&gt;
&lt;p&gt;I will go for CentOS for now..&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;mkdir ~/virt
&lt;span style="color: #008000"&gt;cd&lt;/span&gt; ~/virt
wget http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2.xz
xz -d CentOS-7-x86_64-GenericCloud.qcow2.xz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Create copy-on-write storage for VMs with pristine CentOS as read-only backing-store:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #008000; font-weight: bold"&gt;for&lt;/span&gt; VMID in &lt;span style="color: #666666"&gt;1&lt;/span&gt; &lt;span style="color: #666666"&gt;2&lt;/span&gt; &lt;span style="color: #666666"&gt;3&lt;/span&gt; 4; &lt;span style="color: #008000; font-weight: bold"&gt;do&lt;/span&gt;
    qemu-img create -f qcow2 -o &lt;span style="color: #19177C"&gt;backing_file&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;CentOS-7-x86_64-GenericCloud.qcow2 vm&lt;span style="color: #BB6688; font-weight: bold"&gt;${&lt;/span&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #BB6688; font-weight: bold"&gt;}&lt;/span&gt;.qcow2
&lt;span style="color: #008000; font-weight: bold"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;Qcow2 size&lt;/p&gt;
&lt;p&gt;Note, I did not specify the device size.
By default, VM will get 8GB of "sparse" storage.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In this example setup, all four VMs share the same base (CentOS) image.
Note that blank VM occupy only 200kB:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #19177C"&gt;$ &lt;/span&gt;du -shc CentOS-7-x86_64-GenericCloud.qcow2 vm?.qcow2
959M    CentOS-7-x86_64-GenericCloud.qcow2
196K    vm1.qcow2
196K    vm2.qcow2
196K    vm3.qcow2
196K    vm4.qcow2
960M    total
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="create-minimal-config-drive"&gt;Create minimal config drive&lt;/h3&gt;
&lt;p&gt;This is the &lt;em&gt;important&lt;/em&gt; part.
Config drive is the way to pass information to the VM, "outside" of disk image.
We will create a &lt;em&gt;minimal&lt;/em&gt; iso image that will inject just the ssh public key.
For the full documentation, refer to &lt;a href="http://docs.openstack.org/user-guide/cli_config_drive.html"&gt;Openstack's "Store metadata on a configuration drive"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The content of the ISO image (naturally, fill-in your public key):&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;mkdir -p config-drive/openstack/latest
cat &amp;gt;config-drive/openstack/latest/meta_data.json &lt;span style="color: #BA2121"&gt;&amp;lt;&amp;lt;&amp;#39;EOF&amp;#39;&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;{&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    &amp;quot;public_keys&amp;quot;: {&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;        &amp;quot;bza&amp;quot;: &amp;quot;ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAIEA6rCBkwpHYS073jjOMEUrHAAtA7ovYgBv4FIdb+oD5Yn7UEffzp0fLxhJDkv9hqp3uYk6T/N++HUIeI8oFcfZ1gM00LB70Uv5IkCAy9SztvltOK781NQD1urU8i5j1l9cYLHhyYnGmM9McM77+ZY8IiPSl9jznnRquW7925UrO40= Brano Zarnovican\n&amp;quot;&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    },&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    &amp;quot;uuid&amp;quot;: &amp;quot;83679162-1378-4288-a2d4-70e13ec132aa&amp;quot;&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;}&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;EOF&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="admonition warning"&gt;
&lt;p class="admonition-title"&gt;Valid json&lt;/p&gt;
&lt;p&gt;Be careful to provide a valid json file.
Otherwise, you might waste a lot of time on troubleshooting.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;What's that UUID for?&lt;/p&gt;
&lt;p&gt;That is a mandatory field in Openstack meta_data.json.
It's ok to have some hard-coded value for your local VM.
It is even ok to share the same config drive (and UUID value) for all your VMs.&lt;/p&gt;
&lt;p&gt;Having just the "public_keys" and "uuid" field may be breaking some meta-data standard.
It is working, though.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Create the ISO image:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;mkisofs -R -V config-2 -o config-drive.iso config-drive/
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="admonition warning"&gt;
&lt;p class="admonition-title"&gt;CoreOS is not using cloud-init&lt;/p&gt;
&lt;p&gt;They have their own boot-strapping tool, which &lt;em&gt;resembles&lt;/em&gt; &lt;code&gt;cloud-init&lt;/code&gt;.
Unlike cloud-init, their tool require "config-2" filesystem
label on config drive. Also, their "user_data" file is different.&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id="create-vm"&gt;Create VM&lt;/h3&gt;
&lt;p&gt;Time to tie it all together..&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;1
sudo virt-install --name vm&lt;span style="color: #BB6688; font-weight: bold"&gt;${&lt;/span&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #BB6688; font-weight: bold"&gt;}&lt;/span&gt; --memory &lt;span style="color: #666666"&gt;1024&lt;/span&gt; --vcpus &lt;span style="color: #666666"&gt;1&lt;/span&gt; --import &lt;span style="color: #BB6622; font-weight: bold"&gt;\&lt;/span&gt;
    --disk vm&lt;span style="color: #BB6688; font-weight: bold"&gt;${&lt;/span&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #BB6688; font-weight: bold"&gt;}&lt;/span&gt;.qcow2,bus&lt;span style="color: #666666"&gt;=&lt;/span&gt;virtio &lt;span style="color: #BB6622; font-weight: bold"&gt;\&lt;/span&gt;
    --disk config-drive.iso,device&lt;span style="color: #666666"&gt;=&lt;/span&gt;cdrom,perms&lt;span style="color: #666666"&gt;=&lt;/span&gt;ro &lt;span style="color: #BB6622; font-weight: bold"&gt;\&lt;/span&gt;
    --network &lt;span style="color: #19177C"&gt;network&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;default,model&lt;span style="color: #666666"&gt;=&lt;/span&gt;virtio,mac&lt;span style="color: #666666"&gt;=&lt;/span&gt;52:54:00:00:00:1&lt;span style="color: #BB6688; font-weight: bold"&gt;${&lt;/span&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #BB6688; font-weight: bold"&gt;}&lt;/span&gt; &lt;span style="color: #BB6622; font-weight: bold"&gt;\&lt;/span&gt;
    --noautoconsole
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;virt-manager&lt;/p&gt;
&lt;p&gt;Alternatively, you can create the VM using virt-manager.
Just remember to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;import existing qcow2 image (vmX.qcow2)&lt;/li&gt;
&lt;li&gt;change the MAC address on network interface to 52:54:00:00:00:1X&lt;/li&gt;
&lt;li&gt;add IDE CDROM with config-drive.iso&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="and-we-are-done"&gt;And we are done..&lt;/h2&gt;
&lt;p&gt;If all worked well, you should be able to login..&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;$ ssh centos@vm1
The authenticity of host &amp;#39;vm1 (192.168.122.11)&amp;#39; can&amp;#39;t be established.
ECDSA key fingerprint is SHA256:JrczAJifE04hx+NUF4yTWVHA/6hh+XqELCViluVEW6Q.
ECDSA key fingerprint is MD5:96:f0:85:88:53:3a:c5:47:c3:d2:3e:d8:a6:c1:c6:ff.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added &amp;#39;vm1,192.168.122.11&amp;#39; (ECDSA) to the list of known hosts.
[centos@vm1 ~]$
[centos@vm1 ~]$ sudo -i
[root@vm1 ~]#
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="what-is-vms-base-image"&gt;What is VM's base image ?&lt;/h3&gt;
&lt;p&gt;To query Qcow2 file..&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #19177C"&gt;$ &lt;/span&gt;qemu-img info vm1.qcow2
image: vm1.qcow2
file format: qcow2
virtual size: 8.0G &lt;span style="color: #666666"&gt;(8589934592&lt;/span&gt; bytes&lt;span style="color: #666666"&gt;)&lt;/span&gt;
disk size: 70M
cluster_size: 65536
backing file: CentOS-7-x86_64-GenericCloud.qcow2
Format specific information:
    compat: 1.1
    lazy refcounts: &lt;span style="color: #008000"&gt;false&lt;/span&gt;
&lt;span style="color: #008000"&gt;    &lt;/span&gt;refcount bits: 16
    corrupt: &lt;span style="color: #008000"&gt;false&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="re-image-the-vm"&gt;Re-image the VM&lt;/h3&gt;
&lt;p&gt;Throw away VM's data and start again from pristine image.&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;1

&lt;span style="color: #408080; font-style: italic"&gt;# stop the instance, ok to be &amp;quot;ungraceful&amp;quot; at this point&lt;/span&gt;
sudo virsh destroy vm&lt;span style="color: #BB6688; font-weight: bold"&gt;${&lt;/span&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #BB6688; font-weight: bold"&gt;}&lt;/span&gt;

&lt;span style="color: #408080; font-style: italic"&gt;# destroy and recreate its storage&lt;/span&gt;
&lt;span style="color: #008000"&gt;cd&lt;/span&gt; ~/virt
rm -f vm&lt;span style="color: #BB6688; font-weight: bold"&gt;${&lt;/span&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #BB6688; font-weight: bold"&gt;}&lt;/span&gt;.qcow2
qemu-img create -f qcow2 -o &lt;span style="color: #19177C"&gt;backing_file&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;CentOS-7-x86_64-GenericCloud.qcow2 vm&lt;span style="color: #BB6688; font-weight: bold"&gt;${&lt;/span&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #BB6688; font-weight: bold"&gt;}&lt;/span&gt;.qcow2

&lt;span style="color: #408080; font-style: italic"&gt;# start the instance again&lt;/span&gt;
sudo virsh start vm&lt;span style="color: #BB6688; font-weight: bold"&gt;${&lt;/span&gt;&lt;span style="color: #19177C"&gt;VMID&lt;/span&gt;&lt;span style="color: #BB6688; font-weight: bold"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note, that you don't need to undefine the whole VM.
Destroy or shutdown is enough.
VM will retain hw configuration, network MAC address, etc, but it will loose all data.
You can also switch to a different "base image" while VM is down.&lt;/p&gt;
&lt;h3 id="troubleshooting-cloud-init"&gt;Troubleshooting cloud-init&lt;/h3&gt;
&lt;p&gt;This is tricky.
Something did not work, and now you are not able to login to the VM to have a look at things.
You can still mount the image on host OS and poke around (as root).&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #408080; font-style: italic"&gt;# mount&lt;/span&gt;
modprobe nbd &lt;span style="color: #19177C"&gt;max_part&lt;/span&gt;&lt;span style="color: #666666"&gt;=&lt;/span&gt;63
qemu-nbd -c /dev/nbd0 /home/user/virt/vm1.qcow2
mount /dev/nbd0p1 /mnt/

&lt;span style="color: #408080; font-style: italic"&gt;# umount&lt;/span&gt;
umount /mnt
qemu-nbd -d /dev/nbd0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Just make sure you don't have it mounted on host and guest at the same time..
Cloud-init log file will be in &lt;code&gt;/mnt/var/log/cloud-init.log&lt;/code&gt;,
but you might need to first increase verbosity in &lt;code&gt;/mnt/etc/cloud/cloud.cfg.d/*logging.cfg&lt;/code&gt;&lt;/p&gt;
&lt;h2 id="extras"&gt;Extras&lt;/h2&gt;
&lt;h3 id="static-host-ssh-key"&gt;Static host ssh key&lt;/h3&gt;
&lt;p&gt;It's quite annoying to update &lt;code&gt;known_hosts&lt;/code&gt; file every time I re-image the VM.
One way to fix this is to "give" VM static host keys at first boot via cloud-init.
Its config is in cloud's "user data".&lt;/p&gt;
&lt;div class="codehilite" style="background: #f8f8f8"&gt;&lt;pre style="line-height: 125%"&gt;cat &amp;gt;config-drive/openstack/latest/user_data &lt;span style="color: #BA2121"&gt;&amp;lt;&amp;lt;&amp;#39;EOF&amp;#39;&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;#cloud-config&lt;/span&gt;

&lt;span style="color: #BA2121"&gt;ssh_keys:&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;  rsa_private: |&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    -----BEGIN RSA PRIVATE KEY-----&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    MIIBxwIBAAJhAKD0YSHy73nUgysO13XsJmd4fHiFyQ+00R7VVu2iV9Qcon2LZS/x&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    1cydPZ4pQpfjEha6WxZ6o8ci/Ea/w0n+0HGPwaxlEG2Z9inNtj3pgFrYcRztfECb&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    1j6HCibZbAzYtwIBIwJgO8h72WjcmvcpZ8OvHSvTwAguO2TkR6mPgHsgSaKy6GJo&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    PUJnaZRWuba/HX0KGyhz19nPzLpzG5f0fYahlMJAyc13FV7K6kMBPXTRR6FxgHEg&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    L0MPC7cdqAwOVNcPY6A7AjEA1bNaIjOzFN2sfZX0j7OMhQuc4zP7r80zaGc5oy6W&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    p58hRAncFKEvnEq2CeL3vtuZAjEAwNBHpbNsBYTRPCHM7rZuG/iBtwp8Rxhc9I5w&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    ixvzMgi+HpGLWzUIBS+P/XhekIjPAjA285rVmEP+DR255Ls65QbgYhJmTzIXQ2T9&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    luLvcmFBC6l35Uc4gTgg4ALsmXLn71MCMGMpSWspEvuGInayTCL+vEjmNBT+FAdO&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    W7D4zCpI43jRS9U06JVOeSc9CDk2lwiA3wIwCTB/6uc8Cq85D9YqpM10FuHjKpnP&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    REPPOyrAspdeOAV+6VKRavstea7+2DZmSUgE&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    -----END RSA PRIVATE KEY-----&lt;/span&gt;

&lt;span style="color: #BA2121"&gt;  rsa_public: ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAGEAoPRhIfLvedSDKw7XdewmZ3h8eIXJD7TRHtVW7aJX1ByifYtlL/HVzJ09nilCl+MSFrpbFnqjxyL8Rr/DSf7QcY/BrGUQbZn2Kc22PemAWthxHO18QJvWPocKJtlsDNi3 smoser@localhost&lt;/span&gt;

&lt;span style="color: #BA2121"&gt;  ecdsa_private: |&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    -----BEGIN EC PRIVATE KEY-----&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    MHcCAQEEIIjH3F2tInhb1SpODeeis+7XZexdJQAjVCDUVkfQTjYyoAoGCCqGSM49&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    AwEHoUQDQgAE9cHv9N9K4UF6GyGlHNR82ylKiv715LBZuXOyxezAL+FFiTMo6/qZ&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    y+6rMEJYdkWxqXz4iKkiU/rgmCWvBfC1FQ==&lt;/span&gt;
&lt;span style="color: #BA2121"&gt;    -----END EC PRIVATE KEY-----&lt;/span&gt;

&lt;span style="color: #BA2121"&gt;  ecdsa_public: ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBPXB7/TfSuFBehshpRzUfNspSor+9eSwWblzssXswC/hRYkzKOv6mcvuqzBCWHZFsal8+IipIlP64JglrwXwtRU=&lt;/span&gt;

&lt;span style="color: #BA2121"&gt;EOF&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt; (2016-02-19):&lt;br /&gt;
added note about CoreOS incompatibility with cloud-init.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Braňo Žarnovičan</dc:creator><pubDate>Tue, 10 Nov 2015 00:00:00 +0100</pubDate><guid>tag:zarnovican.github.io,2015-11-10:2015/11/10/run-cloud-image-without-cloud/</guid><category>libvirt</category><category>cloud-init</category><category>config drive</category><category>qcow2</category></item></channel></rss>